{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute seasonal net outgassing of O2 and APO\n",
    "\n",
    "Start with [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) magic; this reloads modules automatically before entering the execution of code and thus enabled development in modules like [util.py](util.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import util\n",
    "\n",
    "import intake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to catalog\n",
    "\n",
    "This notebook uses an [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) to describe file locations. This is the basis of [intake-esm](https://intake-esm.readthedocs.io/en/latest/), though here we are not using `intake-esm` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = intake.open_esm_datastore(util.catalog_json)\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv(util.catalog_csv)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify a subset of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'CanESM5', ## gives non-monotonic coord error for fgco2 in combine_by_coords below \n",
    "    #'CanESM5-CanOE', ## no fgo2 (somehow PM was plotting)\n",
    "    'CNRM-ESM2-1', \n",
    "    'ACCESS-ESM1-5', \n",
    "    'MPI-ESM-1-2-HAM', \n",
    "    'IPSL-CM6A-LR',\n",
    "    'MPI-M.MPI-ESM1-2-HR', \n",
    "    'MPI-ESM1-2-LR', \n",
    "    'NorCPM1', \n",
    "    'NorESM2-LM', \n",
    "    'UKESM1-0-LL',\n",
    "    'MIROC-ES2L',\n",
    "    #'MRI-ESM2-0', ## missing intpp\n",
    "]\n",
    "## others on ESGF showing historical+Omon+fgo2 = EC-Earth3-CC, GFDL-CM4, GFDL-ESM4, IPSL-CM5A2-INCA, IPSL-CM6A-LR-INCA, NorESM2-MM (but of the above ESGF not showing CNRM-ESM2-1, UKESM1-0-LL, MIROC-ES2L, MRI-ESM2-0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test read single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_id = 'UKESM1-0-LL'\n",
    "variable_id = ['fgco2', 'fgo2']\n",
    "time_slice = slice('2005', '2014')\n",
    "experiment_id = 'historical' \n",
    "nmax_members = 4\n",
    "\n",
    "dsi = util.open_cmip_dataset(\n",
    "    source_id=source_id, \n",
    "    variable_id=variable_id, \n",
    "    experiment_id=experiment_id, \n",
    "    time_slice=time_slice, \n",
    "    table_id='Omon',\n",
    "    nmax_members=nmax_members,\n",
    ")\n",
    "dsi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get grid data from each model\n",
    "\n",
    "Skip models where the grid data is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets_fix = {}\n",
    "grid_variables = ['areacello',]\n",
    "for model in models:\n",
    "    dsets_m = [util.get_gridvar(df, model, v) for v in grid_variables]\n",
    "    dsets_m = [ds for ds in dsets_m if ds is not None]\n",
    "    if dsets_m:\n",
    "        dsets_fix[model] = xr.merge(dsets_m)\n",
    "        dsets_fix[model].attrs['source_id'] = model\n",
    "        \n",
    "list(dsets_fix.keys())\n",
    "## somehow PM was getting areacello for MPI-M.MPI-ESM1-2-HR from Ofx - I tried specifying table_id as Ofx here but that did not help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute a region mask for integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmask_definition = 'SET_NET'\n",
    "#rmask_definition = 'global' ### grid-cell area is maxing at 20 degrees in each hemisphere\n",
    "\n",
    "rmask_dict = {}\n",
    "for model in models:    \n",
    "    if model not in dsets_fix:\n",
    "        continue\n",
    "    rmask_dict[model] = util.get_rmask_dict(\n",
    "        dsets_fix[model], \n",
    "        mask_definition=rmask_definition, \n",
    "        plot=True\n",
    "    )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble monthly-mean climatology\n",
    "\n",
    "This code takes the following steps:\n",
    "- Read a dataset for each model\n",
    "- Compute the regional integral \n",
    "- Compute the mean for each month and average across ensemble members\n",
    "- Concatenate the resulting timeseries along a `source_id` dimension\n",
    "\n",
    "Note that the code is set up to cache the resulting dataset; it will optionally read this dataset, rather than recreate it, if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#variable_ids = ['fgco2', 'fgo2'] # , 'intpp', 'fgn2:heatflux,sst,sss']\n",
    "variable_ids = ['intpp']\n",
    "#variable_ids = ['fgn2:tos,sos']\n",
    "    \n",
    "time_slice = slice('2005', '2014') ## for comparison to HIPPO/ORCAS/ATom 2009-2018, pick closest decade\n",
    "experiment_id = 'historical' \n",
    "nmax_members = 4\n",
    "clobber = True\n",
    "\n",
    "# specify models for each variable that have reverse sign convention\n",
    "models_flipsign = {v: [] for v in variable_ids}\n",
    "models_flipsign['fgo2'] = ['NorESM2-LM',]\n",
    "\n",
    "\n",
    "ds_list = []\n",
    "source_id_list = []\n",
    "for source_id in models:    \n",
    "    if source_id not in rmask_dict:\n",
    "        continue\n",
    "        \n",
    "    ds_list_variable_ids = []\n",
    "    for variable_name in variable_ids:\n",
    "        \n",
    "        variable_id = variable_name\n",
    "        derived_var = variable_name\n",
    "        if ':' in variable_name:\n",
    "            variable_id = variable_name.split(':')[-1].split(',')\n",
    "            derived_var = variable_name.split(':')[0]        \n",
    "                \n",
    "        cache_file = (\n",
    "            f'data/cmip6'\n",
    "            f'.{source_id}'\n",
    "            f'.{experiment_id}'\n",
    "            f'.{derived_var}'\n",
    "            f'.{rmask_definition}'\n",
    "            f'.monclim_{time_slice.start}-{time_slice.stop}.zarr'\n",
    "        )\n",
    "        print(cache_file)\n",
    "        if os.path.exists(cache_file) and not clobber:\n",
    "            ds = xr.open_zarr(cache_file)\n",
    "\n",
    "        else:\n",
    "        \n",
    "            dsi = util.open_cmip_dataset(\n",
    "                source_id=source_id, \n",
    "                variable_id=variable_id, \n",
    "                experiment_id=experiment_id, \n",
    "                table_id='Omon',\n",
    "                time_slice=time_slice, \n",
    "                nmax_members=nmax_members,\n",
    "            )\n",
    "            if dsi is None:\n",
    "                print(f'missing: {source_id}, {experiment_id}, {variable_id}')\n",
    "                continue\n",
    "            ### put code below in an elif to allow some models to be missing some variables? as now, crashes if any missing\n",
    "\n",
    "            # compute derived variables\n",
    "            ### need to read in source fields before trying this:\n",
    "            if derived_var == 'fgn2':\n",
    "                print(dsi)\n",
    "                dsi = util.compute_fgn2(dsi)\n",
    "            \n",
    "            elif derived_var == 'fgo2_thermal':\n",
    "                dsi = util.compute_fgo2_thermal(dsi)\n",
    "                \n",
    "            # compute the regional integrals\n",
    "            flipsign = True if source_id in models_flipsign[variable_id] else False            \n",
    "            da = util.compute_regional_integral(\n",
    "                ds=dsi, \n",
    "                variable_id=variable_id,\n",
    "                rmasks=rmask_dict[source_id],\n",
    "                flipsign=flipsign,\n",
    "            )    \n",
    "            \n",
    "            with xr.set_options(keep_attrs=True):\n",
    "                da = da.groupby('time.month').mean().mean('member_id')\n",
    "            \n",
    "            try:\n",
    "                ds = da.to_dataset().drop(['depth']).compute()\n",
    "            except:\n",
    "                print('Depth does not exist in dataset')\n",
    "                \n",
    "            ds.to_zarr(cache_file, mode='w');            \n",
    "            \n",
    "        ds_list_variable_ids.append(ds)\n",
    "    \n",
    "    if ds_list_variable_ids:\n",
    "        source_id_list.append(source_id)\n",
    "\n",
    "    # merge across variables\n",
    "    if ds_list_variable_ids:\n",
    "        ds_list.append(xr.merge(ds_list_variable_ids,))\n",
    "\n",
    "ds = xr.concat(ds_list, dim=xr.DataArray(source_id_list, dims=('source_id'), name='source_id'))    \n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monlabs = np.array([\"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\", \"O\", \"N\", \"D\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = 'fgo2'\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(6, 7), facecolor='w')\n",
    "    \n",
    "for region, ax in zip(ds.region.values, axs.ravel()):\n",
    "    for source_id in ds.source_id.values:\n",
    "        ax.plot(\n",
    "            ds.month-0.5, \n",
    "            ds[field].sel(source_id=source_id, region=region), \n",
    "            marker='.', \n",
    "            linestyle='-',\n",
    "            label=source_id,\n",
    "        )\n",
    "\n",
    "    ax.set_xticks(np.arange(13))    \n",
    "    ax.set_ylabel(f\"{ds[field].attrs['long_name']} [{ds[field].attrs['units']}]\")\n",
    "    ax.set_title(region);\n",
    "    ax.set_xticklabels([])\n",
    "ax.set_xticklabels([f'        {m}' for m in monlabs]+[''])\n",
    "ax.legend(loc=(1.02, 0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = 'fgco2'\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(6, 7), facecolor='w')\n",
    "    \n",
    "monlabs = np.array([\"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\", \"O\", \"N\", \"D\"])\n",
    "\n",
    "for region, ax in zip(ds.region.values, axs.ravel()):\n",
    "    for source_id in ds.source_id.values:\n",
    "        ax.plot(\n",
    "            ds.month-0.5, \n",
    "            ds[field].sel(source_id=source_id, region=region), \n",
    "            marker='.', \n",
    "            linestyle='-',\n",
    "            label=source_id,\n",
    "        )\n",
    "\n",
    "    ax.set_xticks(np.arange(13))    \n",
    "    ax.set_ylabel(f\"{ds[field].attrs['long_name']} [{ds[field].attrs['units']}]\")\n",
    "    ax.set_title(region);\n",
    "    ax.set_xticklabels([])\n",
    "    \n",
    "ax.set_xticklabels([f'        {m}' for m in monlabs]+[''])\n",
    "ax.legend(loc=(1.02, 0));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-sno]",
   "language": "python",
   "name": "conda-env-.conda-sno-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
